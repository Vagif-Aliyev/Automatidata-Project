{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Automatidata project: Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ttxbfHXzB4e"
   },
   "source": [
    "## TASK\n",
    "\n",
    "The request is to build machine learning model to predict whether rider will leave generous tip or not. \n",
    "\n",
    "This is binary classification problem and therefore logistic regression model must be utilized.The following activities are conducted:\n",
    "\n",
    "    1. Importing packages and dataset\n",
    "    2. Data Exploration\n",
    "    2. Feature Engineering\n",
    "    3. Model Construction\n",
    "    4. Model Evaluation\n",
    "    \n",
    "    \n",
    "    \n",
    "**Ethical considerations**\n",
    "\n",
    "Before starting the building model the ethical considerations must be satisfied. Because this is classfication problem the evaluation must be focused to frequency of false positives and positives:\n",
    "\n",
    "  * `False negative`: When the model says a customer will give a tip, but they actually won't.\n",
    "   \n",
    "  * `False positive`: When the model says a customer will not give a tip, but they actually will.  \n",
    "  \n",
    "Drivers who didn't receive tips will probably be upset that the app told them a customer would leave a tip. If it happened often, drivers might not trust the app.\n",
    "Drivers are unlikely to pick up people who are predicted to not leave tips. Customers will have difficulty finding a taxi that will pick them up, and might get angry at the taxi company. Even when the model is correct, people who can't afford to tip will find it more difficult to get taxis, which limits the accessibility of taxi service to those who pay extra.\n",
    "\n",
    "**How to tackle the problem?**\n",
    "\n",
    "It's not good to disincentivize drivers from picking up customers. It could also cause a customer backlash. The problems seem to outweigh the benefits. So building such a model has potential to cause misunderstanding however\n",
    "we can build a model that predicts the most generous (more than 20% of total amount) customers. This could accomplish the goal of helping taxi drivers increase their earnings from tips while preventing the wrongful exclusion of certain people from using taxis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24780,
     "status": "ok",
     "timestamp": 1669031931287,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "fKhnX2Puf4Bt",
    "outputId": "b8c8bbf8-390d-49a7-8c4a-3242114aecf8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data manipulation packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling packages\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "error",
     "timestamp": 1669031931655,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "5weTXGKqa_iG",
    "outputId": "6c91cb73-20d1-43ce-99e1-f28a32e0d4cb"
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "df0 = pd.read_csv('2017_Yellow_Taxi_Trip_Data.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Import predicted fares and mean distance and duration from the previous work (see \"3. Automatidata project-Regression Analysis\")\n",
    "nyc_preds_means = pd.read_csv('nyc_preds_means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_analyze(dataset):\n",
    "    \"\"\"\n",
    "    Function is utilized to get basic descriptive stats from dataframes.\n",
    "    \"\"\"\n",
    "    print(\"1. THE SHAPE OF DATASET\")\n",
    "    print(\"-------------------------\")\n",
    "    print(f\"Number of rows: {dataset.shape[0]} \\nNumber of features: {dataset.shape[1]}\")\n",
    "    print('\\n')\n",
    "    print(\"2. MISSING AND DUPLICATED VALUES\")\n",
    "    print(\"-------------------------\")    \n",
    "    for col in df0.columns:\n",
    "        if dataset.isna().any().sum()==0:\n",
    "            print(f\"Data set doesn't contain any missing value\")\n",
    "            break\n",
    "        elif dataset[col].isna().sum()>0:\n",
    "            print(f\"Number of nulls in {col} column is {dataset[col].isna().sum()}\")\n",
    "    print(f\"Data set has {dataset.duplicated().sum()} duplication.\")\n",
    "    print('\\n')\n",
    "    print(\"3. DATA TYPES\")\n",
    "    print(\"-------------------------\")\n",
    "    print(dataset.dtypes)\n",
    "    print('\\n')\n",
    "    print(\"4. SUMMARY STATISTICS\")\n",
    "    print(\"-------------------------\")\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    display(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. THE SHAPE OF DATASET\n",
      "-------------------------\n",
      "Number of rows: 22699 \n",
      "Number of features: 4\n",
      "\n",
      "\n",
      "2. MISSING AND DUPLICATED VALUES\n",
      "-------------------------\n",
      "Data set doesn't contain any missing value\n",
      "Data set has 0 duplication.\n",
      "\n",
      "\n",
      "3. DATA TYPES\n",
      "-------------------------\n",
      "Unnamed: 0          int64\n",
      "mean_duration     float64\n",
      "mean_distance     float64\n",
      "predicted_fare    float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "4. SUMMARY STATISTICS\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22699.000000</td>\n",
       "      <td>22699.000000</td>\n",
       "      <td>22699.000000</td>\n",
       "      <td>22699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11349.000000</td>\n",
       "      <td>14.460555</td>\n",
       "      <td>2.913313</td>\n",
       "      <td>12.892842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6552.781216</td>\n",
       "      <td>10.080913</td>\n",
       "      <td>3.558993</td>\n",
       "      <td>9.718110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.159844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5674.500000</td>\n",
       "      <td>8.031481</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>7.161890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11349.000000</td>\n",
       "      <td>11.556667</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>9.441588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17023.500000</td>\n",
       "      <td>17.321667</td>\n",
       "      <td>3.115625</td>\n",
       "      <td>13.844181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22698.000000</td>\n",
       "      <td>88.783333</td>\n",
       "      <td>33.920000</td>\n",
       "      <td>62.967275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  mean_duration  mean_distance  predicted_fare\n",
       "count  22699.000000   22699.000000   22699.000000    22699.000000\n",
       "mean   11349.000000      14.460555       2.913313       12.892842\n",
       "std     6552.781216      10.080913       3.558993        9.718110\n",
       "min        0.000000       0.000000       0.000000        3.159844\n",
       "25%     5674.500000       8.031481       1.010000        7.161890\n",
       "50%    11349.000000      11.556667       1.620000        9.441588\n",
       "75%    17023.500000      17.321667       3.115625       13.844181\n",
       "max    22698.000000      88.783333      33.920000       62.967275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_analyze(nyc_preds_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>0</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.540209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>1</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.423650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>2</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>6.621079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>3</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>20.049591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30841670</td>\n",
       "      <td>2</td>\n",
       "      <td>04/15/2017 11:32:20 PM</td>\n",
       "      <td>04/15/2017 11:49:03 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "      <td>4</td>\n",
       "      <td>14.616667</td>\n",
       "      <td>4.435000</td>\n",
       "      <td>15.328859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "0      24870114         2   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "1      35634249         1   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "2     106203690         1   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "3      38942136         2   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "4      30841670         2  04/15/2017 11:32:20 PM  04/15/2017 11:49:03 PM   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "4                1           4.37           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "4             4           112             2         16.5    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "4        0.00           0.0                    0.3         17.80   \n",
       "\n",
       "   Unnamed: 0_y  mean_duration  mean_distance  predicted_fare  \n",
       "0             0      22.847222       3.521667       16.540209  \n",
       "1             1      24.470370       3.108889       16.423650  \n",
       "2             2       7.250000       0.881429        6.621079  \n",
       "3             3      30.250000       3.700000       20.049591  \n",
       "4             4      14.616667       4.435000       15.328859  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = df0.merge(nyc_preds_means,left_index=True,right_index=True)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VZowX9rhU1o"
   },
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D2RvXk0kwsx"
   },
   "source": [
    "The Previous EDA analysis revealed that (see \"1. Automatidata project-EDA Analysis\") riders generally do not pay tip when they make payment with cash. Therefore the model will be build on the riders who pay with credit card. Under feature engineering the following tasks are conducted:\n",
    "\n",
    "1. Isolation of riders who pay with credit card.\n",
    "2. `Tip percent` column.\n",
    "3. `Generous` column by filtering tip percent column.\n",
    "4. Extracting `month` and `day` columns.\n",
    "5. Extracting and transforming the `am_rush`, `pm_rush`, `day_time` and `night_time` columns.\n",
    "6. Variable Encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Isolation of riders who pay with credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "aborted",
     "timestamp": 1669031931657,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "_pmNd78plQYr"
   },
   "outputs": [],
   "source": [
    "df1 = df0[df0['payment_type']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. `Tip percent` column extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1669031931658,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "guanzJd8zBla"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True \n",
    "df1['tip_percent'] = round(df1['tip_amount'] / (df1['total_amount'] - df1['tip_amount']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. `Generous` column extraction [Target Variable]\n",
    "\n",
    "The column should be a binary indicator of whether or not a customer tipped ≥ 20% (0=no, 1=yes).\n",
    "\n",
    "1. Begin by making the `generous` column a copy of the `tip_percent` column.\n",
    "2. Reassign the column by converting it to Boolean (True/False).\n",
    "3. Reassign the column by converting Boolean to binary (1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1669031931658,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "nqDSe0DSGwhB"
   },
   "outputs": [],
   "source": [
    "df1['generous'] = df1['tip_percent']\n",
    "df1['generous'] = (df1['generous'] >= 0.2)\n",
    "df1['generous'] = df1['generous'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkubbZRRKrjO"
   },
   "source": [
    "   ### 3.4. `Day` and `Month` column extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1669031931660,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "OIycxWBMkafJ"
   },
   "outputs": [],
   "source": [
    "df1['tpep_pickup_datetime'] = pd.to_datetime(df1['tpep_pickup_datetime'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df1['tpep_dropoff_datetime'] = pd.to_datetime(df1['tpep_dropoff_datetime'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df1['day'] = df1['tpep_pickup_datetime'].dt.day_name().str.lower()\n",
    "df1['month'] = df1['tpep_pickup_datetime'].dt.strftime('%b').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Extract `am_rush`, `pm_rush`, `day_time` and `night_time` columns.\n",
    "\n",
    "Next, engineer four new columns that represent time of day bins. Each column should contain binary values (0=no, 1=yes) that indicate whether a trip began (picked up) during the following times:\n",
    "\n",
    "`am_rush` = [06:00&ndash;10:00)  \n",
    "`daytime` = [10:00&ndash;16:00)  \n",
    "`pm_rush` = [16:00&ndash;20:00)  \n",
    "`nighttime` = [20:00&ndash;06:00)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1669031931662,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "x8LFySUyprau"
   },
   "outputs": [],
   "source": [
    "df1['am_rush'] = df1['tpep_pickup_datetime'].dt.hour\n",
    "df1['daytime'] = df1['tpep_pickup_datetime'].dt.hour\n",
    "df1['pm_rush'] = df1['tpep_pickup_datetime'].dt.hour\n",
    "df1['nighttime'] = df1['tpep_pickup_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1669031931663,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "oAE4vRz0wGtN"
   },
   "outputs": [],
   "source": [
    "# Define the functions:\n",
    "\n",
    "# _____ Function 1 ______:\n",
    "def am_rush(hour):\n",
    "    if 6 <= hour['am_rush'] < 10:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "# _____ Function 2 ______:\n",
    "def pm_rush(hour):\n",
    "    if 16 <= hour['pm_rush'] < 20:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "# _____ Function 3 ______:\n",
    "def daytime(hour):\n",
    "    if 10 <= hour['daytime'] < 16:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "# _____ Function 4 ______:\n",
    "def nighttime(hour):\n",
    "    if 20 <= hour['nighttime'] < 24:\n",
    "        val = 1\n",
    "    elif 0 <= hour['nighttime'] < 6:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1669031931663,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "sWFojyk9xdDY"
   },
   "outputs": [],
   "source": [
    "# Apply the functions to columns:\n",
    "df1['am_rush'] = df1.apply(am_rush, axis=1)\n",
    "df1['pm_rush'] = df1.apply(pm_rush, axis=1)\n",
    "df1['daytime'] = df1.apply(daytime, axis=1)\n",
    "df1['nighttime'] = df1.apply(nighttime, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 25715,
     "status": "aborted",
     "timestamp": 1669031931669,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "jWxemeyl4vwQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "      <th>tip_percent</th>\n",
       "      <th>generous</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>am_rush</th>\n",
       "      <th>daytime</th>\n",
       "      <th>pm_rush</th>\n",
       "      <th>nighttime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-25 08:55:43</td>\n",
       "      <td>2017-03-25 09:09:47</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>0</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.540209</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>mar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-11 14:53:28</td>\n",
       "      <td>2017-04-11 15:19:58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>1</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.423650</td>\n",
       "      <td>0.238</td>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>apr</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-15 07:26:56</td>\n",
       "      <td>2017-12-15 07:34:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>2</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>6.621079</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0</td>\n",
       "      <td>friday</td>\n",
       "      <td>dec</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-07 13:17:59</td>\n",
       "      <td>2017-05-07 13:48:14</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>3</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>20.049591</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>sunday</td>\n",
       "      <td>may</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23345809</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-25 20:34:11</td>\n",
       "      <td>2017-03-25 20:42:11</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>5</td>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>9.844915</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>mar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0      24870114         2  2017-03-25 08:55:43   2017-03-25 09:09:47   \n",
       "1      35634249         1  2017-04-11 14:53:28   2017-04-11 15:19:58   \n",
       "2     106203690         1  2017-12-15 07:26:56   2017-12-15 07:34:08   \n",
       "3      38942136         2  2017-05-07 13:17:59   2017-05-07 13:48:14   \n",
       "5      23345809         2  2017-03-25 20:34:11   2017-03-25 20:42:11   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "5                6           2.30           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "5           161           236             1          9.0    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "5        2.06           0.0                    0.3         12.36   \n",
       "\n",
       "   Unnamed: 0_y  mean_duration  mean_distance  predicted_fare  tip_percent  \\\n",
       "0             0      22.847222       3.521667       16.540209        0.200   \n",
       "1             1      24.470370       3.108889       16.423650        0.238   \n",
       "2             2       7.250000       0.881429        6.621079        0.199   \n",
       "3             3      30.250000       3.700000       20.049591        0.300   \n",
       "5             5      11.855376       2.052258        9.844915        0.200   \n",
       "\n",
       "   generous       day month  am_rush  daytime  pm_rush  nighttime  \n",
       "0         1  saturday   mar        1        0        0          0  \n",
       "1         1   tuesday   apr        0        1        0          0  \n",
       "2         0    friday   dec        1        0        0          0  \n",
       "3         1    sunday   may        0        1        0          0  \n",
       "5         1  saturday   mar        0        0        0          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droping Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15265 entries, 0 to 22698\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   VendorID         15265 non-null  int64  \n",
      " 1   passenger_count  15265 non-null  int64  \n",
      " 2   RatecodeID       15265 non-null  int64  \n",
      " 3   PULocationID     15265 non-null  int64  \n",
      " 4   DOLocationID     15265 non-null  int64  \n",
      " 5   Unnamed: 0_y     15265 non-null  int64  \n",
      " 6   mean_duration    15265 non-null  float64\n",
      " 7   mean_distance    15265 non-null  float64\n",
      " 8   predicted_fare   15265 non-null  float64\n",
      " 9   generous         15265 non-null  int64  \n",
      " 10  day              15265 non-null  object \n",
      " 11  month            15265 non-null  object \n",
      " 12  am_rush          15265 non-null  int64  \n",
      " 13  daytime          15265 non-null  int64  \n",
      " 14  pm_rush          15265 non-null  int64  \n",
      " 15  nighttime        15265 non-null  int64  \n",
      "dtypes: float64(3), int64(11), object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['Unnamed: 0_x', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "             'payment_type', 'trip_distance', 'store_and_fwd_flag', 'payment_type',\n",
    "             'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "             'improvement_surcharge', 'total_amount', 'tip_percent']\n",
    "\n",
    "df1 = df1.drop(drop_cols, axis=1)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Variable encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVs01W-Iitu7"
   },
   "source": [
    "Many of the columns are categorical and will need to be dummied (converted to binary). Some of these columns are numeric, but they actually encode categorical information, such as `RatecodeID` and the pickup and dropoff locations. To make these columns recognizable to the `get_dummies()` function as categorical variables, you'll first need to convert them to `type(str)`. \n",
    "\n",
    "1. Define a variable called `cols_to_str`, which is a list of the numeric columns that contain categorical information and must be converted to string: `RatecodeID`, `PULocationID`, `DOLocationID`.\n",
    "2. Write a for loop that converts each column in `cols_to_str` to string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 25714,
     "status": "aborted",
     "timestamp": 1669031931670,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "FbB4AfATHqjC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15265 entries, 0 to 22698\n",
      "Columns: 348 entries, passenger_count to month_sep\n",
      "dtypes: bool(338), float64(3), int64(7)\n",
      "memory usage: 6.2 MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Define list of cols to convert to string\n",
    "cols_to_str = ['RatecodeID', 'PULocationID', 'DOLocationID', 'VendorID']\n",
    "\n",
    "# 2. Convert each column to string\n",
    "for col in cols_to_str:\n",
    "    df1[col] = df1[col].astype('str')\n",
    "    \n",
    "# 3. Convert categoricals to binary\n",
    "df2 = pd.get_dummies(df1, drop_first=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZfNE37b-LlJ"
   },
   "source": [
    "### 4.1. Selecting the evaluation metric\n",
    "\n",
    "Before modeling, decision must be made on an evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 25704,
     "status": "aborted",
     "timestamp": 1669031931672,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "4mRefXCF-K_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generous\n",
       "1    0.526368\n",
       "0    0.473632\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['generous'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjgkLrOf_OrE"
   },
   "source": [
    "A little over half of the customers in this dataset were \"generous\" (tipped ≥ 20%). The dataset is very nearly balanced.\n",
    "\n",
    "To determine a metric, consider the cost of both kinds of model error:\n",
    "* False positives (the model predicts a tip ≥ 20%, but the customer does not give one)\n",
    "* False negatives (the model predicts a tip < 20%, but the customer gives more)\n",
    "\n",
    "False positives are worse for cab drivers, because they would pick up a customer expecting a good tip and then not receive one, frustrating the driver.\n",
    "\n",
    "False negatives are worse for customers, because a cab driver would likely pick up a different customer who was predicted to tip more&mdash;even when the original customer would have tipped generously.\n",
    "\n",
    "**The stakes are relatively even. You want to help taxi drivers make more money, but you don't want this to anger customers. Your metric should weigh both precision and recall equally. Which metric is this?**\n",
    "\n",
    "**Exemplar response:**  F<sub>1</sub> score is the metric that places equal weight on true postives and false positives, and so therefore on precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jzGjOS8iiv"
   },
   "source": [
    "### 4.2. Train and Test Data Preparation\n",
    "\n",
    "For this part the parameters are set shown below:\n",
    "\n",
    "* random_state=42\n",
    "* test_size=0.2: 20% of total records is split as test data \n",
    "* stratify=y: To divide records proportionally between train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 25703,
     "status": "aborted",
     "timestamp": 1669031931672,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "qLbapbSWDUL-"
   },
   "outputs": [],
   "source": [
    "y = df2['generous']\n",
    "\n",
    "X = df2.drop('generous', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12212, 347)\n",
      "X_test: (3053, 347)\n",
      "y_train: (12212,)\n",
      "y_test: (3053,)\n"
     ]
    }
   ],
   "source": [
    "#Get size of samples\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 25701,
     "status": "aborted",
     "timestamp": 1669031931672,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "Vj5rJWOv5O3d"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiation of random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "cv_params = {'max_depth': [None],\n",
    "             'max_features': [1.0, 2.0],\n",
    "             'max_samples': [0.7],\n",
    "             'min_samples_leaf': [1],\n",
    "             'min_samples_split': [2],\n",
    "             'n_estimators': [200,300,400]\n",
    "             }\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "scoring = ['accuracy','recall','precision','f1']\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "rf_cv=GridSearchCV(estimator=rf, param_grid=cv_params, scoring=scoring, cv=4, refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 25701,
     "status": "aborted",
     "timestamp": 1669031931673,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "OXuBiTGi5ZHn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "12 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 2.0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.69390763 0.69554537 0.69489027        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.77893591 0.782514   0.78095831        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.68372121 0.68443562 0.68418447        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/vagifaliyev/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.728156   0.73012116 0.72930077        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 4s, sys: 1.85 s, total: 9min 6s\n",
      "Wall time: 9min 7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [1.0, 2.0],\n",
       "                         &#x27;max_samples&#x27;: [0.7], &#x27;min_samples_leaf&#x27;: [1],\n",
       "                         &#x27;min_samples_split&#x27;: [2],\n",
       "                         &#x27;n_estimators&#x27;: [200, 300, 400]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;recall&#x27;, &#x27;precision&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [1.0, 2.0],\n",
       "                         &#x27;max_samples&#x27;: [0.7], &#x27;min_samples_leaf&#x27;: [1],\n",
       "                         &#x27;min_samples_split&#x27;: [2],\n",
       "                         &#x27;n_estimators&#x27;: [200, 300, 400]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;recall&#x27;, &#x27;precision&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [None], 'max_features': [1.0, 2.0],\n",
       "                         'max_samples': [0.7], 'min_samples_leaf': [1],\n",
       "                         'min_samples_split': [2],\n",
       "                         'n_estimators': [200, 300, 400]},\n",
       "             refit='f1', scoring=['accuracy', 'recall', 'precision', 'f1'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1. Model Tuning\n",
    "\n",
    "First, examine the best estimates across cross validation conducted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=1.0, max_samples=0.7, n_estimators=300,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=1.0, max_samples=0.7, n_estimators=300,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_features=1.0, max_samples=0.7, n_estimators=300,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiation of random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "cv_params = {'max_depth': [None],\n",
    "             'max_features': [1.0],\n",
    "             'max_samples': [0.7],\n",
    "             'min_samples_leaf': [1],\n",
    "             'min_samples_split': [2],\n",
    "             'n_estimators': [300]\n",
    "             }\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "scoring = ['accuracy','recall','precision','f1']\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "rf_tuned_cv=GridSearchCV(estimator=rf, param_grid=cv_params, scoring=scoring, cv=4, refit='f1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 41s, sys: 418 ms, total: 3min 41s\n",
      "Wall time: 3min 43s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [1.0],\n",
       "                         &#x27;max_samples&#x27;: [0.7], &#x27;min_samples_leaf&#x27;: [1],\n",
       "                         &#x27;min_samples_split&#x27;: [2], &#x27;n_estimators&#x27;: [300]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;recall&#x27;, &#x27;precision&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None], &#x27;max_features&#x27;: [1.0],\n",
       "                         &#x27;max_samples&#x27;: [0.7], &#x27;min_samples_leaf&#x27;: [1],\n",
       "                         &#x27;min_samples_split&#x27;: [2], &#x27;n_estimators&#x27;: [300]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;recall&#x27;, &#x27;precision&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [None], 'max_features': [1.0],\n",
       "                         'max_samples': [0.7], 'min_samples_leaf': [1],\n",
       "                         'min_samples_split': [2], 'n_estimators': [300]},\n",
       "             refit='f1', scoring=['accuracy', 'recall', 'precision', 'f1'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# rf_tuned_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 25699,
     "status": "aborted",
     "timestamp": 1669031931674,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "6JsLR2-uy9p1"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "path = '/Users/vagifaliyev/Desktop/Automatidata-project/'\n",
    "\n",
    "\n",
    "def write_pickle(path, model_object, save_name:str):\n",
    "    '''\n",
    "    save_name is a string.\n",
    "    '''\n",
    "    with open(path + save_name + '.pickle', 'wb') as to_write:\n",
    "        pickle.dump(model_object, to_write)\n",
    "\n",
    "        \n",
    "def read_pickle(path, saved_model_name:str):\n",
    "    '''\n",
    "    saved_model_name is a string.\n",
    "    '''\n",
    "    with open(path + saved_model_name + '.pickle', 'rb') as to_read:\n",
    "        model = pickle.load(to_read)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(path=path, model_object=rf_tuned_cv, save_name=\"Tuned RF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1669031931846,
     "user": {
      "displayName": "Jim McCoy",
      "userId": "05540602321492626965"
     },
     "user_tz": 360
    },
    "id": "dE6oXEJJiT2R"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiate the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=0)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'learning_rate': [0.01, 0.1, 0.3],\n",
    "             'max_depth': [8],\n",
    "             'min_child_weight': [2],\n",
    "             'n_estimators': [500]\n",
    "             }\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "xgb_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=4, refit='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the model to the `X_train` and `y_train` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 52.2 s, total: 2min 56s\n",
      "Wall time: 30.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=0, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.3], &#x27;max_depth&#x27;: [8],\n",
       "                         &#x27;min_child_weight&#x27;: [2], &#x27;n_estimators&#x27;: [500]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=0, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.3], &#x27;max_depth&#x27;: [8],\n",
       "                         &#x27;min_child_weight&#x27;: [2], &#x27;n_estimators&#x27;: [500]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=0, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=0, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=0, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.3], 'max_depth': [8],\n",
       "                         'min_child_weight': [2], 'n_estimators': [500]},\n",
       "             refit='f1', scoring=['accuracy', 'precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best score from this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1. Model Tuning\n",
    "\n",
    "First, examine the best estimates across cross validation conducted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 2,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=0)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "cv_params = {'learning_rate': [0.01],\n",
    "             'max_depth': [8],\n",
    "             'min_child_weight': [2],\n",
    "             'n_estimators': [500]\n",
    "             }\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "xgb_tuned_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=4, refit='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.4 s, sys: 21.6 s, total: 1min 11s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=0, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01], &#x27;max_depth&#x27;: [8],\n",
       "                         &#x27;min_child_weight&#x27;: [2], &#x27;n_estimators&#x27;: [500]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=0, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01], &#x27;max_depth&#x27;: [8],\n",
       "                         &#x27;min_child_weight&#x27;: [2], &#x27;n_estimators&#x27;: [500]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=0, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=0, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=0, ...),\n",
       "             param_grid={'learning_rate': [0.01], 'max_depth': [8],\n",
       "                         'min_child_weight': [2], 'n_estimators': [500]},\n",
       "             refit='f1', scoring=['accuracy', 'precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# xgb_tuned_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(path=path, model_object=xgb_tuned_cv, save_name=\"Tuned XGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the best average score across all the validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_scores(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "    model_name (string): what you want the model to be called in the output table\n",
    "    model_object: a fit GridSearchCV object\n",
    "    metric (string): precision, recall, f1, or accuracy\n",
    "\n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "\n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy],\n",
    "                        },\n",
    "                       )\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "    model_name (string): Your choice: how the model will be named in the output table\n",
    "    preds: numpy array of test predictions\n",
    "    y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "    table: a pandas df of precision, recall, f1, and accuracy scores for your model\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_test_data, preds)\n",
    "    precision = precision_score(y_test_data, preds)\n",
    "    recall = recall_score(y_test_data, preds)\n",
    "    f1 = f1_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy]\n",
    "                        })\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds = xgb_cv.best_estimator_.predict(X_test)\n",
    "rf_preds = rf_cv.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_result = get_train_scores('Train-RF CV', rf_cv, 'f1')\n",
    "xgb_result=get_train_scores('Train-XGB CV', xgb_tuned_cv, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train-RF CV</td>\n",
       "      <td>0.684436</td>\n",
       "      <td>0.782514</td>\n",
       "      <td>0.730121</td>\n",
       "      <td>0.695545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train-XGB CV</td>\n",
       "      <td>0.691413</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>0.740615</td>\n",
       "      <td>0.706027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test-RF test</td>\n",
       "      <td>0.679446</td>\n",
       "      <td>0.794026</td>\n",
       "      <td>0.732281</td>\n",
       "      <td>0.694399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test-XGB test</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.812072</td>\n",
       "      <td>0.743166</td>\n",
       "      <td>0.704553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  precision    recall        F1  accuracy\n",
       "0    Train-RF CV   0.684436  0.782514  0.730121  0.695545\n",
       "0   Train-XGB CV   0.691413  0.797449  0.740615  0.706027\n",
       "0   Test-RF test   0.679446  0.794026  0.732281  0.694399\n",
       "0  Test-XGB test   0.685039  0.812072  0.743166  0.704553"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_scores = get_test_scores('Test-RF test', rf_preds, y_test)\n",
    "xgb_test_scores=get_test_scores('Test-XGB test', xgb_preds, y_test)\n",
    "results = pd.concat([rf_result,xgb_result, rf_test_scores,xgb_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZjClJnncJ-j"
   },
   "source": [
    "**Exemplar response:** The F<sub>1</sub> score is ~0.01 lower than the random forest model. Both models are acceptable, but the random forest model is the champion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a confusion matrix of the champion model's predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array of values for confusion matrix\n",
    "cm = confusion_matrix(y_test, rf_preds, labels=rf1.classes_)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=rf1.classes_, \n",
    "                             )\n",
    "disp.plot(values_format='');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplar response:** The model is almost twice as likely to predict a false positive than it is to predict a false negative. Therefore, type I errors are more common. This is less desirable, because it's better for a driver to be pleasantly surprised by a generous tip when they weren't expecting one than to be disappointed by a low tip when they were expecting a generous one. However, the overall performance of this model is satisfactory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature importance\n",
    "\n",
    "Use the `feature_importances_` attribute of the best estimator object to inspect the features of your final model. You can then sort them and plot the most important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf1.best_estimator_.feature_importances_\n",
    "rf_importances = pd.Series(importances, index=X_test.columns)\n",
    "rf_importances = rf_importances.sort_values(ascending=False)[:15]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "rf_importances.plot.bar(ax=ax)\n",
    "ax.set_title('Feature importances')\n",
    "ax.set_ylabel('Mean decrease in impurity')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ill21hQ4ej9-"
   },
   "source": [
    "### **Task 4. Conclusion**\n",
    "\n",
    "In this step, use the results of the models above to formulate a conclusion. Consider the following questions:\n",
    "\n",
    "**Exemplar responses:**\n",
    "1. **Would you recommend using this model? Why or why not?**  \n",
    "Yes, this is model performs acceptably. Its F<sub>1</sub> score was 0.7235 and it had an overall accuracy of 0.6865. It correctly identified ~78% of the actual responders in the test set, which is 48% better than a random guess. It may be worthwhile to test the model with a select group of taxi drivers to get feedback.  \n",
    "\n",
    "\n",
    "2. **What was your highest scoring model doing? Can you explain how it was making predictions?**   \n",
    "Unfortunately, random forest is not the most transparent machine learning algorithm. We know that `VendorID`, `predicted_fare`, `mean_duration`, and `mean_distance` are the most important features, but we don't know how they influence tipping. This would require further exploration. It is interesting that `VendorID` is the most predictive feature. This seems to indicate that one of the two vendors tends to attract more generous customers. It may be worth performing statistical tests on the different vendors to examine this further.  \n",
    "\n",
    "\n",
    "3. **Are there new features that you can engineer that might improve model performance?**  \n",
    "There are almost always additional features that can be engineered, but hopefully the most obvious ones were generated during the first round of modeling. In our case, we could try creating three new columns that indicate if the trip distance is short, medium, or far. We could also engineer a column that gives a ratio that represents (the amount of money from the fare amount to the nearest higher multiple of \\\\$5) / fare amount. For example, if the fare were \\\\$12, the value in this column would be 0.25, because \\\\$12 to the nearest higher multiple of \\\\$5 (\\\\$15) is \\\\$3, and \\\\$3 divided by \\\\$12 is 0.25. The intuition for this feature is that people might be likely to simply round up their tip, so journeys with fares with values just under a multiple of \\\\$5 may have lower tip percentages than those with fare values just over a multiple of \\\\$5. We could also do the same thing for fares to the nearest \\\\$10.\n",
    "\n",
    "$$\n",
    "round5\\_ratio = \\frac{amount\\ of\\ money\\ from\\ the\\ fare\\ amount\\ to\\ the\\ nearest\\ higher\\ multiple\\ of\\ \\$5}{fare\\ amount}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "    <summary><h5>HINT</h5></summary>\n",
    "    $$ = \\frac{5 - (fare\\ mod\\ 5)}{fare\\ amount}$$\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "4. **What features would you want to have that would likely improve the performance of your model?**   \n",
    "It would probably be very helpful to have past tipping behavior for each customer. It would also be valuable to have accurate tip values for customers who pay with cash.\n",
    "It would be helpful to have a lot more data. With enough data, we could create a unique feature for each pickup/dropoff combination.\n",
    "\n",
    "\n",
    "Remember, sometimes your data simply will not be predictive of your chosen target. This is common. Machine learning is a powerful tool, but it is not magic. If your data does not contain predictive signal, even the most complex algorithm will not be able to deliver consistent and accurate predictions. Do not be afraid to draw this conclusion. Even if you cannot use the model to make strong predictions, was the work done in vain? What insights can you report back to stakeholders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
